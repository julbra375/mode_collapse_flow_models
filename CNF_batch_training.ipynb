{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10f3aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: equinox in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
      "Requirement already satisfied: jax!=0.7.0,!=0.7.1,>=0.4.38 in /usr/local/lib/python3.12/dist-packages (from equinox) (0.7.2)\n",
      "Requirement already satisfied: jaxtyping>=0.2.20 in /usr/local/lib/python3.12/dist-packages (from equinox) (0.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from equinox) (4.15.0)\n",
      "Requirement already satisfied: wadler-lindig>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from equinox) (0.1.7)\n",
      "Requirement already satisfied: jaxlib<=0.7.2,>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox) (0.7.2)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox) (0.5.4)\n",
      "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox) (2.0.2)\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox) (1.16.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install equinox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cefba78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e9a567ed-7a1e-4d4c-b9c5-c80ebf2dbef5\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-e9a567ed-7a1e-4d4c-b9c5-c80ebf2dbef5\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2535520808.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    162\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    163\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1a1571",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mount failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3360560710.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# import sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# sys.path.append('/content/drive/My Drive/julian_scripts')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/julian_scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a518593",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4077092967.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConcatMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSharedWeightAutoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCNF_batch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNF_reverse_kl_batch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msample_multimodal_gaussian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultimodal_gaussian_logpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefine_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_hypersphere_modes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_3_orthogonal_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scripts'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import equinox as eqx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scripts.models import LinearFlow, ConcatMLP, Autoencoder, SharedWeightAutoencoder, MLP\n",
    "from scripts.losses import CNF_batch_loss, CNF_reverse_kl_batch_loss\n",
    "from scripts.distributions import sample_multimodal_gaussian, multimodal_gaussian_logpdf, define_distributions, get_hypersphere_modes, find_3_orthogonal_points\n",
    "from scripts.training import train_CNF, train_CNF_parallel, train_CNF_analytic_parallel\n",
    "from scripts.utils.ode_solver import phi\n",
    "from scripts.utils.plotting import make_fig_ax\n",
    "from scripts.utils.distribution_statistics import stable_rank_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bd7ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel args:\\nantisym=(dim, key, init_var)\\nlinear=(dim, key, init_var, init_weight)\\nconcat=(datasize, width, depth, key, init_std)\\nmlp=(dim, width, depth, hidden_act, final_act, init_std, key)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = {\n",
    "    'linear': LinearFlow,\n",
    "    'mlp': MLP,\n",
    "    'autoencoder': Autoencoder,\n",
    "    'shared_weight_autoencoder': SharedWeightAutoencoder,\n",
    "    'concat': ConcatMLP\n",
    "}\n",
    "\n",
    "calc_rank_dict = {\n",
    "    'linear': lambda weight_list: stable_rank_svd(jnp.array(weight_list[0])),\n",
    "    'linear_with_bias': lambda weight_list: stable_rank_svd(jnp.array(weight_list[0])),\n",
    "    'linear_antisym': lambda weight_list: jnp.array([stable_rank_svd(weight_list[0]), stable_rank_svd((weight_list[0] - weight_list[0].T)/2)]),\n",
    "    'mlp': lambda weight_list: jnp.array([stable_rank_svd(weight_list[0]), stable_rank_svd(weight_list[2])]),\n",
    "    'autoencoder': lambda weight_list: jnp.array([stable_rank_svd(weight_list[0]), stable_rank_svd(weight_list[1])]),\n",
    "    'shared_weight_autoencoder': lambda weight_list: stable_rank_svd(jnp.array(weight_list[0])),\n",
    "    'concat':  lambda weight_list: jnp.array([stable_rank_svd(weight_list[0]), stable_rank_svd(weight_list[5])])\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "model args:\n",
    "antisym=(dim, key, init_var)\n",
    "linear=(dim, key, init_var, init_weight)\n",
    "concat=(datasize, width, depth, key, init_std)\n",
    "mlp=(dim, width, depth, hidden_act, final_act, init_std, key)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2716cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnf_model(model_skeleton, key):\n",
    "    \"\"\"Create a single CNF model\"\"\"\n",
    "    return model_skeleton(key)\n",
    "\n",
    "def unbatch_models(batched_models):\n",
    "    \"\"\"\n",
    "    Convert batched pytree back to list of individual models.\n",
    "    \n",
    "    Input: SharedWeightAutoencoder(W=f32[5,2,2], b=f32[5,2], d=weak_i32[5], h=weak_i32[5])\n",
    "    Output: [model_0, model_1, model_2, model_3, model_4]\n",
    "    \"\"\"\n",
    "    num_models = batched_models.W.shape[0]\n",
    "    \n",
    "    models = []\n",
    "    for i in range(num_models):\n",
    "        # Extract i-th slice from each array in the pytree\n",
    "        model_i = jax.tree_util.tree_map(\n",
    "            lambda x: x[i] if hasattr(x, '__getitem__') else x,\n",
    "            batched_models\n",
    "        )\n",
    "        models.append(model_i)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657ec47",
   "metadata": {},
   "source": [
    "#### Train parallel with backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e71e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initalize_and_train_parallel(num_models, dim, radii, training_iterations, key, num_repeats, model_type, model_args, mode_arrangement, unimodal_init=False, batch_size=128, verbose=True, eps_deg=0):\n",
    "\n",
    "    key, train_key, mode_key1, mode_key2 = jax.random.split(key, 4)\n",
    "\n",
    "    # Initialise models\n",
    "    model_skeleton = lambda init_key: model_dict[model_type](init_key, *model_args)\n",
    "    # model_skeleton = lambda init_key: LinearFlow(dim=dim, key=init_key, init_var=0.01)\n",
    "    train_key, *keys = jax.random.split(key, num_repeats+1)\n",
    "    # models_list = [create_cnf_model(model_skeleton, k) for k in keys]\n",
    "    # We want the num_models models initialised with num_repeats different initialisations\n",
    "    models_list = [create_cnf_model(model_skeleton, keys[k%num_repeats]) for k in range(radii.shape[0])]\n",
    "    models = jax.tree_util.tree_map(lambda *leaves: jnp.stack(leaves), *models_list)\n",
    "\n",
    "    # Define initial distribution\n",
    "    identity = jnp.identity(dim)\n",
    "    num_initial_modes = 2\n",
    "    if unimodal_init:\n",
    "        get_initial_samples = lambda key, initial_modes: jax.random.multivariate_normal(key, mean=jnp.zeros(dim), cov=jnp.identity(dim), shape=batch_size)\n",
    "    else: \n",
    "        if mode_arrangement == 'orthogonal':\n",
    "            initial_modes_batch = jnp.tile(identity[jnp.arange(num_initial_modes)], (num_models, 1, 1))*radii.reshape((num_models, 1, 1))\n",
    "        elif mode_arrangement == 'orthogonal_eps_overlap':\n",
    "            initial_modes = identity[jnp.arange(num_initial_modes)]\n",
    "            eps_rad = jnp.deg2rad(eps_deg)\n",
    "            eps_rotation = jnp.array([[jnp.cos(eps_rad), 0, -jnp.sin(eps_rad), 0],\n",
    "                                    [0, jnp.cos(eps_rad), 0, -jnp.sin(eps_rad)],\n",
    "                                    [jnp.sin(eps_rad), 0 , jnp.cos(eps_rad), 0],\n",
    "                                    [0, jnp.sin(eps_rad), 0, jnp.cos(eps_rad)]])\n",
    "            identity_reduced = jnp.identity(dim-4)\n",
    "            zeros = jnp.zeros((dim-4, 4))\n",
    "            rotation_block = jnp.block([[eps_rotation, zeros.T], [zeros, identity_reduced]])\n",
    "            initial_modes = (rotation_block @ initial_modes.T).T\n",
    "            initial_modes_batch = jnp.tile(initial_modes, (num_models, 1, 1))*radii.reshape((num_models, 1, 1))\n",
    "        elif mode_arrangement == 'symmetric':\n",
    "            initial_modes_batch = jnp.tile((jnp.repeat(identity, 2, axis=0) * (-1)**jnp.arange(2*dim)[:, jnp.newaxis])[jnp.arange(num_initial_modes)], (num_models, 1, 1))*radii.reshape((num_models, 1, 1))\n",
    "        elif mode_arrangement == 'random_hypersphere_orthogonal':\n",
    "            initial_modes1 = jax.vmap(lambda radius: get_hypersphere_modes(dim, 1, radius, jax.random.PRNGKey(0))[0])(radii)\n",
    "            new_initial_modes = jax.vmap(lambda initial_mode1: find_3_orthogonal_points(initial_mode1.reshape((-1, 1))))(initial_modes1)\n",
    "\n",
    "            def stack_modes(initial, new_modes):\n",
    "                initial_modes = jnp.stack([initial, new_modes[0]])\n",
    "                target_modes = new_modes[1:]\n",
    "                return initial_modes, target_modes\n",
    "\n",
    "            initial_modes_batch, target_modes_batch = jax.vmap(stack_modes)(initial_modes1, new_initial_modes)\n",
    "\n",
    "        initial_covs = jnp.tile(jnp.identity(dim), (num_initial_modes, 1, 1))\n",
    "        initial_weights = jnp.ones(num_initial_modes)\n",
    "        get_initial_samples = lambda key, initial_modes: sample_multimodal_gaussian(key, means=initial_modes, covs=initial_covs, weights=initial_weights, num_samples=batch_size)\n",
    "\n",
    "    # Define target distribution\n",
    "    num_target_modes = 2\n",
    "    if mode_arrangement == 'orthogonal':\n",
    "        target_modes_batch = jnp.tile(identity[jnp.arange(num_initial_modes, num_initial_modes+num_target_modes)], (num_models, 1, 1))*radii.reshape((num_models, 1, 1))\n",
    "    elif mode_arrangement == 'orthogonal_eps_overlap':\n",
    "        target_modes_batch = jnp.tile(identity[jnp.arange(num_initial_modes, num_initial_modes+num_target_modes)], (num_models, 1, 1))*radii.reshape((num_models, 1, 1))\n",
    "    elif mode_arrangement == 'symmetric':\n",
    "        target_modes_batch = jnp.tile((jnp.repeat(identity, 2, axis=0) * (-1)**jnp.arange(2*dim)[:, jnp.newaxis])[jnp.arange(num_initial_modes, num_initial_modes+num_target_modes)], (num_models, 1, 1))*radii.reshape((num_models, 1, 1))\n",
    "    target_covs = jnp.tile(jnp.identity(dim), (num_target_modes, 1, 1)) # dimension=dim, num_modes=2\n",
    "    target_weights = jnp.ones(num_target_modes)\n",
    "    target_pdf = lambda x, target_modes: multimodal_gaussian_logpdf(x, target_modes, target_covs, target_weights)\n",
    "\n",
    "    # Loss fn\n",
    "    ts_forwards = [0, 1, 0.01]\n",
    "    loss_fn = lambda model, zs, key, target_modes: CNF_reverse_kl_batch_loss(model, zs, ts_forwards, lambda x: target_pdf(x, target_modes), key, approx=True)\n",
    "\n",
    "    # Training params\n",
    "    lr = 1e-3\n",
    "    optimizer = optax.sgd(lr)\n",
    "    calc_ranks_parallel = lambda weight_list: stable_rank_svd(jnp.array(weight_list))\n",
    "\n",
    "    trained_models, loss_history, weight_history, rank_history, grads_history = train_CNF_parallel(models, get_initial_samples, loss_fn,\n",
    "                                                            optimizer, train_key, calc_ranks_parallel,\n",
    "                                                            initial_modes_batch, target_modes_batch, training_iterations, save_weights_and_grads=False,\n",
    "                                                            verbose=verbose)\n",
    "    return trained_models, loss_history, weight_history, rank_history, grads_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378ad1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initalize_and_train_parallel_analytic(num_models, dim, radius, num_initial_modes, num_target_modes, training_iterations, key, model_type, model_args, mode_arrangement, batch_size, optimizer, unimodal_init=False, verbose=True, eps_deg=0):\n",
    "    \"\"\"\"\n",
    "    Train batch of models with analytic gradient with different seeds. Dim, radius, number of modes is constant\n",
    "    \"\"\"\n",
    "    key, train_key, *init_keys = jax.random.split(key, num_models + 2)\n",
    "\n",
    "    # Initialise models\n",
    "    model_skeleton = lambda init_key: model_dict[model_type](init_key, *model_args)\n",
    "    models_list = [create_cnf_model(model_skeleton, init_keys[k]) for k in range(num_models)]\n",
    "    models = jax.tree_util.tree_map(lambda *leaves: jnp.stack(leaves), *models_list)\n",
    "\n",
    "    # Define initial distribution\n",
    "    initial_modes_single, target_modes_single, _, _, _, _ = define_distributions(dim, radius, radius, num_initial_modes, num_target_modes, mode_arrangement, num_samples=1024,  key=jax.random.PRNGKey(0), unimodal_init=unimodal_init, eps_deg=eps_deg)\n",
    "    initial_modes_batch = jnp.tile(initial_modes_single, (num_models, 1, 1))\n",
    "    target_modes_batch = jnp.tile(target_modes_single, (num_models, 1, 1))\n",
    "\n",
    "    # Fn to calculate ranks\n",
    "    calc_ranks_parallel = lambda weight_list: stable_rank_svd(jnp.array(weight_list))\n",
    "\n",
    "    trained_models, loss_history, weight_history, biases_history, rank_history, grads_history = train_CNF_analytic_parallel(models, initial_modes_batch, target_modes_batch, \n",
    "                                                                                                            optimizer, train_key, calc_ranks_parallel, training_iterations, \n",
    "                                                                                                            batch_size, save_weights_and_grads=True, save_biases=False, verbose=verbose)\n",
    "    return trained_models, loss_history, weight_history, rank_history, grads_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bf1cd2",
   "metadata": {},
   "source": [
    "#### Train using backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806dc5a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initalize_and_train_parallel_analytic() got an unexpected keyword argument 'radii'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m eps_deg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      6\u001b[0m mode_arrangement \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morthogonal_eps_overlap\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m models, losses, weights, ranks, grads \u001b[38;5;241m=\u001b[39m \u001b[43minitalize_and_train_parallel_analytic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradii\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mtraining_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mnum_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_repeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_arrangement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode_arrangement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43munimodal_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps_deg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps_deg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: initalize_and_train_parallel_analytic() got an unexpected keyword argument 'radii'"
     ]
    }
   ],
   "source": [
    "num_repeats = 10\n",
    "radii = jnp.repeat(jnp.arange(4, 9), num_repeats)\n",
    "dim = 30\n",
    "model_args = (dim, 0.5)\n",
    "eps_deg = 2\n",
    "mode_arrangement = 'orthogonal_eps_overlap'\n",
    "models, losses, weights, ranks, grads = initalize_and_train_parallel(num_models=50, dim=dim, radii=radii, \n",
    "                                                                     training_iterations=5000, key=jax.random.PRNGKey(0), \n",
    "                                                                     num_repeats=num_repeats, model_type='linear', \n",
    "                                                                     model_args=model_args, mode_arrangement=mode_arrangement, \n",
    "                                                                     unimodal_init=False, batch_size=128, verbose=True, eps_deg=eps_deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea6b9c",
   "metadata": {},
   "source": [
    "#### Train with analytic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bbf6ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Grad Norm: 28.50529:   1%|          | 27/5000 [00:12<39:17,  2.11it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39msgd(lr)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Train models\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m models, losses, weights, ranks, grads \u001b[38;5;241m=\u001b[39m \u001b[43minitalize_and_train_parallel_analytic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_initial_modes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_target_modes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                                                              \u001b[49m\u001b[43mtraining_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_arrangement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                                                              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munimodal_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps_deg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m, in \u001b[0;36minitalize_and_train_parallel_analytic\u001b[1;34m(num_models, dim, radius, num_initial_modes, num_target_modes, training_iterations, key, model_type, model_args, mode_arrangement, batch_size, optimizer, unimodal_init, verbose, eps_deg)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Fn to calculate ranks\u001b[39;00m\n\u001b[0;32m     18\u001b[0m calc_ranks_parallel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m weight_list: stable_rank_svd(jnp\u001b[38;5;241m.\u001b[39marray(weight_list))\n\u001b[1;32m---> 20\u001b[0m trained_models, loss_history, weight_history, biases_history, rank_history, grads_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_CNF_analytic_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_modes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_modes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                                                                                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_ranks_parallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                                                                                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights_and_grads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_biases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_models, loss_history, weight_history, rank_history, grads_history\n",
      "File \u001b[1;32mc:\\Users\\julia\\OneDrive\\Documents\\Uni\\Paris\\Project\\Code\\scripts\\training.py:350\u001b[0m, in \u001b[0;36mtrain_CNF_analytic_parallel\u001b[1;34m(models, initial_modes_batch, target_modes_batch, optimizer, key, calc_rank_parallel, training_iterations, num_samples, save_weights_and_grads, save_biases, verbose)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;66;03m# Calculate Ranks if function provided\u001b[39;00m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m calc_rank_parallel:\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;66;03m# Assumes calc_rank_parallel takes a batch of weights and returns batch of ranks\u001b[39;00m\n\u001b[1;32m--> 350\u001b[0m         rank_history\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcalc_rank_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# Update Progress Bar\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m, in \u001b[0;36minitalize_and_train_parallel_analytic.<locals>.<lambda>\u001b[1;34m(weight_list)\u001b[0m\n\u001b[0;32m     15\u001b[0m target_modes_batch \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mtile(target_modes_single, (num_models, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Fn to calculate ranks\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m calc_ranks_parallel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m weight_list: \u001b[43mstable_rank_svd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m trained_models, loss_history, weight_history, biases_history, rank_history, grads_history \u001b[38;5;241m=\u001b[39m train_CNF_analytic_parallel(models, initial_modes_batch, target_modes_batch, \n\u001b[0;32m     21\u001b[0m                                                                                                         optimizer, train_key, calc_ranks_parallel, training_iterations, \n\u001b[0;32m     22\u001b[0m                                                                                                         batch_size, save_weights_and_grads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_biases\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_models, loss_history, weight_history, rank_history, grads_history\n",
      "File \u001b[1;32mc:\\Users\\julia\\OneDrive\\Documents\\Uni\\Paris\\Project\\Code\\scripts\\utils\\distribution_statistics.py:245\u001b[0m, in \u001b[0;36mstable_rank_svd\u001b[1;34m(A, eps)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mCompute stable rank using explicit SVD.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03mThis is mathematically equivalent but can be more interpretable.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# Compute SVD\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m _, s, _ \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Sum of squared singular values = Frobenius norm squared\u001b[39;00m\n\u001b[0;32m    248\u001b[0m sum_sv_sq \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39msum(s \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(_cls, U, S, Vh)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "# Model/problem setup\n",
    "num_models = 30\n",
    "dim = 20\n",
    "radius = 10\n",
    "num_initial_modes = 3\n",
    "num_target_modes = 3\n",
    "model_type = 'linear'\n",
    "model_args = (dim, 0.01)\n",
    "mode_arrangement = 'orthogonal'\n",
    "\n",
    "# Training params\n",
    "training_iterations = 5000\n",
    "batch_size = 10000\n",
    "lr = 1e-3\n",
    "optimizer = optax.sgd(lr)\n",
    "\n",
    "# Train models\n",
    "models, losses, weights, ranks, grads = initalize_and_train_parallel_analytic(num_models, dim, radius, num_initial_modes, num_target_modes, \n",
    "                                                                              training_iterations, key, model_type, model_args, mode_arrangement, \n",
    "                                                                              batch_size, optimizer, unimodal_init=False, verbose=True, eps_deg=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc6fee",
   "metadata": {},
   "source": [
    "#### Unbatch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc55f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unbatched_models = unbatch_models(models)\n",
    "for i, model in enumerate(unbatched_models):\n",
    "    save_losses = losses[:, i]\n",
    "    save_weights = weights[:, i]\n",
    "    save_biases = jnp.empty(0)\n",
    "    save_ranks = jnp.empty(0) #ranks[:, i]\n",
    "    save_grads = jnp.empty(0) #grads[:, i]\n",
    "    to_save = {\n",
    "        'model': model,\n",
    "        'losses': save_losses,\n",
    "        'weights': save_weights,\n",
    "        'biases': save_biases,\n",
    "        'weight_ranks': save_ranks,\n",
    "        'gradients': save_grads\n",
    "    }\n",
    "    eqx.tree_serialise_leaves(f'Linear_10D_10radius_3modes_orthogonal_seed{i}.eqx', to_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
